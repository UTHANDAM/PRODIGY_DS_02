# ğŸ§¹ Prodigy Infotech â€“ Data Science Internship (Task 2)

<img src="Prodigy_task_02.jpg" alt="Banner" style="width:100%; max-width:700px;">

Hey there ğŸ‘‹  
I'm **Uthandam**, and this repository contains my submission for **Task 2** of the **Prodigy InfoTech Data Science Internship**.

In this task, I performed **Data Cleaning** and **Exploratory Data Analysis (EDA)** on a real-world dataset from Kaggle to discover insights, relationships, and trends hidden in the data.

---

## ğŸ“œ Task Description

> Perform data cleaning and exploratory data analysis (EDA) on a dataset of your choice, such as the Titanic dataset from Kaggle. Explore the relationships between variables and identify patterns and trends in the data.

ğŸ“Œ **Dataset Reference:**  
[https://www.kaggle.com/c/titanic/data](https://www.kaggle.com/c/titanic/data)

---

## ğŸŒ About the Dataset

For this task, I used the famous [**Titanic - Machine Learning from Disaster**](https://www.kaggle.com/c/titanic/data) dataset â€” a classic for data scientists and machine learning practitioners. It provides details of passengers aboard the Titanic and aims to predict survival based on their attributes.

The dataset includes three files:

- `train.csv` â€“ Training data with known survival outcomes
- `test.csv` â€“ Test data for prediction (used in this task)
- `gender_submission.csv` â€“ Sample submission file

ğŸ§© I focused on the **`test.csv`** file for EDA. Key features include:

- `PassengerId`  
- `Pclass` (Ticket Class)  
- `Name`  
- `Sex`  
- `Age`  
- `SibSp` (Siblings/Spouses aboard)  
- `Parch` (Parents/Children aboard)  
- `Fare`  
- `Embarked` (Port of Embarkation)

---

## ğŸ§° Tools & Libraries

This project was developed using **Python** in a **Jupyter Notebook** environment with the following libraries:

- `pandas` and `numpy` â€“ Data handling and preprocessing  
- `matplotlib` and `seaborn` â€“ Visualization and plotting  
- `missingno` â€“ To visually inspect missing data  
- Jupyter Notebook â€“ For documenting analysis step-by-step

---

## ğŸ” What I Did â€“ A Quick Walkthrough

### 1. ğŸ“‚ Understanding the Data
- Loaded the `test.csv` file  
- Explored shape, columns, and types  
- Used `.info()` and `.describe()` for basic insights

### 2. ğŸ§¼ Cleaning the Data
- Detected and handled missing values (`Age`, `Fare`, `Embarked`)  
- Filled nulls using techniques like median imputation  
- Converted data types where needed  
- Ensured consistency for analysis

### 3. ğŸ“Š Visualizing Patterns
- Countplots for `Pclass`, `Sex`, and `Embarked`  
- Boxplots for fare distribution across classes  
- Histograms to visualize age spread  
- Heatmaps to identify correlation between numeric variables  
- Pie charts to understand categorical proportions

---

## ğŸ’¡ Key Takeaways

- **Class Difference**: Ticket class impacts features like fare and likely survival  
- **Gender Balance**: Slightly more males than females in the dataset  
- **Missing Values**: Age was the most common missing feature â€” median-based imputation worked well  
- **Fare Outliers**: Found some extreme fare values that were visualized and analyzed  
- **Age Distribution**: Passengers span a wide age range, with clustering around young adults

---

## ğŸ¯ Conclusion

This task allowed me to practice and demonstrate core data science steps:
- Data ingestion  
- Cleaning and preprocessing  
- Exploratory Data Analysis  
- Visual storytelling using plots

I enjoyed exploring the Titanic dataset and surfacing insights from raw data. This task sharpened my understanding of EDA and reinforced the importance of prepping data before diving into modeling.


---

Thanks for checking out my work! ğŸ™Œ  
Feel free to explore the notebook and reach out for any feedback or collaboration ğŸš€
